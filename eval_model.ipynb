{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# LSTM\n",
    "path_lstm  = 'models/LSTM/LSTM_0904_2210'\n",
    "# RNN\n",
    "path_rnn   = 'models/RNN/RNN_0904_2100'\n",
    "# RSNNs\n",
    "path_if    = 'models/RSNN/RSNN_1015_1353_if'\n",
    "path_lif   = 'models/RSNN/RSNN_1014_2127_lif'\n",
    "path_alif  = 'models/RSNN/RSNN_1015_1408_alif'\n",
    "path_dexat = 'models/RSNN/RSNN_1002_1731_dexat'\n",
    "# path_texat = 'models/RSNN/RSNN_1012_1512_texat'  # 128\n",
    "path_texat = 'models/RSNN/RSNN_1029_1232_texat'  # 4096\n",
    "\n",
    "paths_dict = {\n",
    "    'lstm':  path_lstm,\n",
    "    'rnn':   path_rnn,\n",
    "    'if':    path_if,\n",
    "    'lif':   path_lif,\n",
    "    'alif':  path_alif,\n",
    "    'dexat': path_dexat,\n",
    "    'texat': path_texat,\n",
    "}\n",
    "\n",
    "options_dict = dict()\n",
    "for model_name, model_path in paths_dict.items():\n",
    "    path_options = os.path.join(model_path, 'options.json')\n",
    "    with open(path_options, 'r') as file:\n",
    "        options = json.load(file)\n",
    "    options = SimpleNamespace(**options)\n",
    "    # print(f'options: \\n{options}')\n",
    "    \n",
    "    options_dict[model_name] = options\n",
    "    \n",
    "    \n",
    "# change device to cpu\n",
    "# for model_name, options in options_dict.items():\n",
    "#     print('---')\n",
    "#     print(model_name)\n",
    "    \n",
    "#     options.device = 'cpu'\n",
    "#     print(options.device)\n",
    "    \n",
    "print('options loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rnn_models = ['lstm', 'rnn']\n",
    "rsnn_models = ['if', 'lif', 'alif', 'dexat', 'texat']\n",
    "\n",
    "\n",
    "# which_model = 'lstm'\n",
    "# which_model = 'rnn'\n",
    "\n",
    "# which_model = 'if'\n",
    "# which_model = 'lif'\n",
    "# which_model = 'alif'\n",
    "# which_model = 'dexat'\n",
    "which_model = 'texat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = options_dict[which_model]\n",
    "\n",
    "print(f'using which_model={which_model}')\n",
    "print(f'using options={options}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from place_cells import PlaceCells\n",
    "from trajectory_generator import TrajectoryGenerator\n",
    "from model import RNN, LSTM\n",
    "from model_rsnn import RSNN\n",
    "# from trainer import Trainer\n",
    "\n",
    "place_cells = PlaceCells(options)\n",
    "\n",
    "# =========================================\n",
    "# =======load multiple models==========\n",
    "# models_dict = dict()\n",
    "# for model_name, options in options_dict.items():\n",
    "#     print('------')\n",
    "#     print(f'options.RNN_type={options.RNN_type}')\n",
    "    \n",
    "#     if options.RNN_type == 'RNN':\n",
    "#         model = RNN(options, place_cells)\n",
    "#     elif options.RNN_type == 'LSTM':\n",
    "#         model = LSTM(options, place_cells)\n",
    "#     elif options.RNN_type == 'RSNN':\n",
    "#         print(f'options.neuron_type={options.neuron_type}')\n",
    "#         model = RSNN(options, place_cells)\n",
    "#     else:\n",
    "#         raise NotImplementedError\n",
    "\n",
    "#     print(f'options.device={options.device}')\n",
    "#     model = model.to(options.device)\n",
    "    \n",
    "#     # load model\n",
    "#     model_pth = os.path.join(options.save_dir, options.run_ID)\n",
    "#     model_pth = os.path.join(model_pth, 'model.pth')\n",
    "#     model.load_state_dict(torch.load(model_pth))\n",
    "    \n",
    "#     models_dict[model_name] = model\n",
    "# print('models loaded')\n",
    "# =========================================\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# =======load one model==========\n",
    "print(options.RNN_type)\n",
    "    \n",
    "if options.RNN_type == 'RNN':\n",
    "    model = RNN(options, place_cells)\n",
    "elif options.RNN_type == 'LSTM':\n",
    "    model = LSTM(options, place_cells)\n",
    "elif options.RNN_type == 'RSNN':\n",
    "    print(options.neuron_type)\n",
    "    model = RSNN(options, place_cells)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "print(options.device)\n",
    "model = model.to(options.device)\n",
    "\n",
    "# load model\n",
    "model_pth = os.path.join(options.save_dir, options.run_ID)\n",
    "####################################################################\n",
    "model_pth = os.path.join(model_pth, 'model.pth')\n",
    "# model_pth = os.path.join(model_pth, 'model_200.pth')\n",
    "# model_pth = os.path.join(model_pth, 'model_100.pth')\n",
    "####################################################################\n",
    "model.load_state_dict(torch.load(model_pth))\n",
    "print('model loaded')\n",
    "# =========================================\n",
    "\n",
    "\n",
    "trajectory_generator = TrajectoryGenerator(options, place_cells)\n",
    "# trainer = Trainer(options, model, trajectory_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.sequence_length = 100\n",
    "print(f'options.sequence_length={options.sequence_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot a few sample trajectories\n",
    "inputs, pos, pc_outputs = trajectory_generator.get_test_batch()\n",
    "# inputs, pos, pc_outputs = trajectory_generator.get_test_batch(batch_size=2000)\n",
    "us = place_cells.us.cpu()\n",
    "pos = pos.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "# plt.scatter(us[:,0], us[:,1], c='lightblue', label='$N_\\\\text{p}$ place cell centers')\n",
    "plt.scatter(us[:,0], us[:,1], c='lightblue', label='Place cell centers')\n",
    "\n",
    "start = 15\n",
    "end = start + 1\n",
    "for i in range(start, end):\n",
    "    print(f'i={i}')\n",
    "    \n",
    "    plt.plot(pos[:,i,0], pos[:,i,1], c='black', label='Trajectory', linewidth=3)\n",
    "    plt.scatter(pos[0,i,0], pos[0,i,1], c='blue', marker='o', label='Start of trajectory', s=70)\n",
    "    plt.scatter(pos[-1,i,0], pos[-1,i,1], c='red', marker='^', label='End of trajectory', s=70)\n",
    "    if i == start:\n",
    "        # plt.legend(loc='upper right', bbox_to_anchor=(1.53, 1.02))\n",
    "        plt.legend(loc='upper left')\n",
    "        # plt.legend()\n",
    "        \n",
    "# plt.xlabel('$L$')\n",
    "# plt.ylabel('$L$')\n",
    "plt.xticks([]);\n",
    "plt.yticks([]);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/task/env.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/task/env.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs.shape)\n",
    "print(pos.shape)\n",
    "print(pc_outputs.shape)\n",
    "print(pc_outputs[:, start, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few place cell outputs\n",
    "# pc_outputs = pc_outputs.reshape(-1, options.Np).detach().cpu()\n",
    "pc_outputs0 = pc_outputs[:, start, :].reshape(-1, options.Np).detach().cpu()\n",
    "\n",
    "print(f'pc_outputs0.shape={pc_outputs0.shape}')\n",
    "# print(pc_outputs[::100].shape)\n",
    "\n",
    "# pc = place_cells.grid_pc(pc_outputs[::100], res=100)\n",
    "pc = place_cells.grid_pc(pc_outputs0, res=500)\n",
    "print(f'pc.shape={pc.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, init_actv = inputs\n",
    "print(init_actv.shape)\n",
    "\n",
    "init_actv0 = init_actv[start].reshape(-1, options.Np).detach().cpu()\n",
    "print(init_actv0.shape)\n",
    "\n",
    "pc0 = place_cells.grid_pc(init_actv0, res=500)\n",
    "print(f'pc0.shape={pc0.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7*1.5, 3*1.5))\n",
    "\n",
    "for i in range(21):\n",
    "    plt.subplot(3, 7, i+1)\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.imshow(pc0[0], cmap='jet', interpolation='gaussian')\n",
    "        plt.title('$\\\\boldsymbol{p}_0$')\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        im = plt.imshow(pc[i-1], cmap='jet', interpolation='gaussian')\n",
    "        plt.title(f'$\\\\boldsymbol{{p}}_{{{i}}}$')\n",
    "        plt.axis('off')\n",
    "    # plt.colorbar(im, fraction=0.15, pad=0.04)\n",
    "\n",
    "# plt.suptitle('Place cell outputs', fontsize=16)\n",
    "# plt.show()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('place_cell_act.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pc0[0], cmap='jet', interpolation='gaussian')\n",
    "# plt.title('$\\\\boldsymbol{p}_0$')\n",
    "plt.axis('off')\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/task/p0.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/task/p0.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pc[0], cmap='jet', interpolation='gaussian')\n",
    "plt.title('$\\\\boldsymbol{p}_{1}$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/task/p1.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/task/p1.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pc[-1], cmap='jet', interpolation='gaussian')\n",
    "length = pc.shape[0]\n",
    "print(f'length={length}')\n",
    "\n",
    "# plt.title('$\\\\boldsymbol{p}_{100}$')\n",
    "plt.axis('off')\n",
    "\n",
    "# plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/task/p100.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/task/p100.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate path integration performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models_dict.items():\n",
    "    model.eval()\n",
    "    print(model_name)\n",
    "    print(f'model.training={model.training}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options.sequence_length = 20\n",
    "# options.sequence_length = 50\n",
    "options.sequence_length = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'options.sequence_length={options.sequence_length}')\n",
    "\n",
    "inputs, pos, pc_outputs = trajectory_generator.get_test_batch()\n",
    "\n",
    "for model_name, model in models_dict.items():\n",
    "    print('------')\n",
    "    print(model_name)\n",
    "    \n",
    "    loss, err = model.compute_loss(inputs, pc_outputs, pos)\n",
    "    \n",
    "    print(f'loss={loss:.3f}')\n",
    "    print(f'err={err:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute predicted paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "inputs, pos, pc_outputs = trajectory_generator.get_test_batch()\n",
    "\n",
    "pos = pos.cpu()\n",
    "print(f'pos.shape={pos.shape}')\n",
    "\n",
    "pred_pos_dict = dict()\n",
    "for model_name, model in models_dict.items():\n",
    "    print('------')\n",
    "    print(model_name)\n",
    "    \n",
    "    # inputs[0] = inputs[0].to(options_dict[model_name].device)\n",
    "    # inputs[1] = inputs[1].to(options_dict[model_name].device)\n",
    "    pred_pos = place_cells.get_nearest_cell_pos(model.predict(inputs)).cpu()\n",
    "    print(f'pred_pos.shape={pred_pos.shape}')\n",
    "    pred_pos_dict[model_name] = pred_pos\n",
    "\n",
    "us = place_cells.us.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot error with respect to each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(scalars, weight=0.8):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1.0 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "        \n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_dict = dict()\n",
    "\n",
    "for model_name, pred_pos in pred_pos_dict.items():\n",
    "    err = torch.sqrt(((pos - pred_pos)**2).sum(-1)).mean(-1)\n",
    "\n",
    "    print(model_name)\n",
    "    print(f'err.shape={err.shape}')\n",
    "\n",
    "    err_dict[model_name] = err\n",
    "\n",
    "for model_name, err in err_dict.items():\n",
    "    if not model_name == 'if':\n",
    "        plt.plot(err, alpha=0.2, c='blue')\n",
    "        plt.plot(smooth(err, weight=0.5), label=model_name)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['Blue', 'Orange', 'Green', 'Red', 'Purple', 'Brown', 'Cyan']\n",
    "# colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#17becf']\n",
    "# darker versions:\n",
    "# colors = ['#134d72', '#b3540a', '#194019', '#851b1b', '#5c4380', '#573d30', '#89497e', '#4c4c4c', '#107288']\n",
    "# colors = ['#184f81', '#cc660b', '#238327', '#aa2121', '#775593', '#70483d', '#b9609b', '#666666', '#1392a8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "# plt.scatter(us[:,0], us[:,1], s=20, alpha=0.5, c='lightgrey')\n",
    "plt.scatter(us[:,0], us[:,1], c='lightblue', label='$N_\\\\text{p}$ place cell centers')\n",
    "\n",
    "start = 125\n",
    "end = start + 1\n",
    "# for i in range(start, end):\n",
    "# for i in [start, 80, 135]:\n",
    "for i in [start, 20, 62]:\n",
    "    plt.plot(pos[:,i,0], pos[:,i,1], c='black', label='G.T. path', linewidth=3)\n",
    "    \n",
    "    for j, (model_name, pred_pos) in enumerate(pred_pos_dict.items()):\n",
    "        if model_name in rsnn_models:\n",
    "            label = 'Int. path of ' + model_name.upper() + '-RSNN'\n",
    "        else:\n",
    "            label = 'Int. path of ' + model_name.upper()\n",
    "\n",
    "        color = colors[j]\n",
    "        \n",
    "        # plt.plot(\n",
    "        #     pred_pos[:,i,0], pred_pos[:,i,1], \n",
    "        #     '.-', color=color, label=label, \n",
    "        #     linewidth=2,\n",
    "        #     alpha=0.7,\n",
    "        # )\n",
    "        \n",
    "        # =================================\n",
    "        # T=100\n",
    "        if model_name in ['lstm', 'rnn', 'texat']:\n",
    "            plt.plot(\n",
    "                pred_pos[:,i,0], pred_pos[:,i,1], \n",
    "                '.-', color=color, label=label, \n",
    "                linewidth=2,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "        else:\n",
    "            # Dummy plot for legend\n",
    "            plt.plot(\n",
    "                [], [], \n",
    "                '.-', color=color, label='(Failed) ' + label, \n",
    "                linewidth=2,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "        # =================================\n",
    "            \n",
    "    if i == start:\n",
    "        # plt.legend(loc='upper left')\n",
    "        plt.legend(loc='lower right')\n",
    "        \n",
    "# plt.xlabel('$L$')\n",
    "# plt.ylabel('$L$')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim([-options.box_width/2, options.box_width/2])\n",
    "plt.ylim([-options.box_height/2, options.box_height/2])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/int_path_results/int_path_t' + str(options.sequence_length) + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "# plt.scatter(us[:,0], us[:,1], s=20, alpha=0.5, c='lightgrey')\n",
    "plt.scatter(us[:,0], us[:,1], c='lightblue', label='$N_\\\\text{p}$ place cell centers')\n",
    "\n",
    "for i in range(1):\n",
    "    plt.plot(pos[:,i,0], pos[:,i,1], c='black', label='G.T. path', linewidth=2)\n",
    "    \n",
    "    for model_name, pred_pos in pred_pos_dict.items():\n",
    "        if model_name == 'lstm':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='blue', label='Integrated path using LSTM')\n",
    "        elif model_name == 'rnn':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='orange', label='Integrated path using RNN')\n",
    "        elif model_name == 'texat':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='green', label='Integrated path using TEXAT-RSNN')\n",
    "            \n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "        \n",
    "plt.xlabel('$L$')\n",
    "plt.ylabel('$L$')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim([-options.box_width/2, options.box_width/2])\n",
    "plt.ylim([-options.box_height/2, options.box_height/2])\n",
    "# plt.legend()\n",
    "\n",
    "# plt.savefig('images/int_path_lstm_rnn_texat.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "# plt.scatter(us[:,0], us[:,1], s=20, alpha=0.5, c='lightgrey')\n",
    "plt.scatter(us[:,0], us[:,1], c='lightblue', label='$N_\\\\text{p}$ place cell centers')\n",
    "\n",
    "start = 66\n",
    "end = start + 3\n",
    "for i in range(start, end):\n",
    "    plt.plot(pos[:,i,0], pos[:,i,1], c='black', label='G.T. path', linewidth=2)\n",
    "    \n",
    "    for model_name, pred_pos in pred_pos_dict.items():\n",
    "        if model_name == 'if':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='blue', label='Integrated path using IF-RSNN')\n",
    "        elif model_name == 'lif':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='orange', label='Integrated path using LIF-RSNN')\n",
    "        elif model_name == 'alif':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='green', label='Integrated path using ALIF-RSNN')\n",
    "        elif model_name == 'dexat':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='purple', label='Integrated path using DEXAT-RSNN')\n",
    "        elif model_name == 'texat':\n",
    "            plt.plot(pred_pos[:,i,0], pred_pos[:,i,1], '.-', color='red', label='Integrated path using TEXAT-RSNN')\n",
    "            \n",
    "    if i == start:\n",
    "        plt.legend()\n",
    "        \n",
    "plt.xlabel('$L$')\n",
    "plt.ylabel('$L$')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlim([-options.box_width/2, options.box_width/2])\n",
    "plt.ylim([-options.box_height/2, options.box_height/2])\n",
    "\n",
    "# plt.savefig('images/int_path_rsnns.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted place cell outputs\n",
    "inputs, pos, pc_outputs = trajectory_generator.get_test_batch()\n",
    "\n",
    "preds = model.predict(inputs)\n",
    "preds = preds.reshape(-1, options.Np).detach().cpu()\n",
    "\n",
    "pc_outputs = model.softmax(pc_outputs).reshape(-1, options.Np).cpu()\n",
    "\n",
    "pc_pred = place_cells.grid_pc(preds[:100])\n",
    "pc = place_cells.grid_pc(pc_outputs[:100])\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(8):\n",
    "    plt.subplot(2,8,i+9)\n",
    "    plt.imshow(pc_pred[2*i], cmap='jet')\n",
    "    if i == 0:\n",
    "        plt.ylabel('Predicted')\n",
    "    plt.axis('off')\n",
    "    \n",
    "for i in range(8):\n",
    "    plt.subplot(2,8,i+1)\n",
    "    plt.imshow(pc[2*i], cmap='jet', interpolation='gaussian')\n",
    "    if i == 0:\n",
    "        plt.ylabel('True')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.suptitle('Place cell outputs', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratemaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute ratemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from visualize import compute_ratemaps, plot_ratemaps, rgb, compute_ratemaps_rsnn\n",
    "from visualize import compute_ratemaps  # lstm, rnn\n",
    "from visualize import compute_ratemaps_rsnn  # rsnns\n",
    "\n",
    "res = 20\n",
    "n_avg = 50\n",
    "# res = 50\n",
    "# n_avg = 100\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    # dict of (Ng, res, res) np.array\n",
    "    ratemaps = compute_ratemaps_rsnn(model, trajectory_generator, options, res=res, n_avg=n_avg)\n",
    "    for key, rm in ratemaps.items():\n",
    "        print(f'{key}, rm.shape={rm.shape}')\n",
    "else:\n",
    "    # (Ng, res, res) np.array\n",
    "    ratemaps = compute_ratemaps(model, trajectory_generator, options, res=res, n_avg=n_avg)\n",
    "    print(f'ratemaps.shape={ratemaps.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Ratemap\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    # dict of Ratemap\n",
    "    rate_maps = {}\n",
    "    for key, rm in ratemaps.items():\n",
    "        rate_maps[key] = Ratemap(options=options, res=res, ratemaps=rm)\n",
    "else:\n",
    "    # Ratemap\n",
    "    rate_map = Ratemap(options=options, res=res, ratemaps=ratemaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save ratemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    # if not ('model.pth' in model_pth):\n",
    "    #     pkl_name = f'data/rate_maps/rate_maps_{which_model}_{model_pth[-7:-4]}.pkl'\n",
    "    # else:\n",
    "    #     pkl_name = f'data/rate_maps/rate_maps_{which_model}.pkl'\n",
    "        \n",
    "    pkl_name = f'data/rate_maps/rate_maps_{which_model}_Ng128.pkl'\n",
    "    \n",
    "    with open(pkl_name, 'wb') as f:\n",
    "        # dict of Ratemap\n",
    "        pickle.dump(rate_maps, f)\n",
    "    print('saved pickle to ' + pkl_name)\n",
    "    \n",
    "else:\n",
    "    pkl_name = f'data/rate_maps/rate_map_{which_model}.pkl'\n",
    "    with open(pkl_name, 'wb') as f:\n",
    "        # Ratemap\n",
    "        pickle.dump(rate_map, f)\n",
    "    print('saved pickle to ' + pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## load ratemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_labels = {\n",
    "    'spike_in': 'ISL', \n",
    "    'spike_rnn_1': 'RSL 1',\n",
    "    'spike_rnn_2': 'RSL 2',\n",
    "    'spike_rnn_3': 'RSL 3',\n",
    "    'mem_out': 'OL',\n",
    "}\n",
    "\n",
    "lstm_rnn_models = ['lstm', 'rnn']\n",
    "rsnn_models = ['if', 'lif', 'alif', 'dexat', 'texat']\n",
    "\n",
    "\n",
    "# which_model = 'lstm'\n",
    "# which_model = 'rnn'\n",
    "\n",
    "# which_model = 'if'\n",
    "# which_model = 'lif'\n",
    "# which_model = 'alif'\n",
    "# which_model = 'dexat'\n",
    "which_model = 'texat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    pkl_name = f'data/rate_maps/rate_maps_{which_model}.pkl'\n",
    "    \n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        # dict of Ratemap\n",
    "        rate_maps = pickle.load(f)\n",
    "    print('loaded pickle from ' + pkl_name)\n",
    "    \n",
    "else:\n",
    "    pkl_name = f'data/rate_maps/rate_map_{which_model}.pkl'\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        # Ratemap\n",
    "        rate_map = pickle.load(f)\n",
    "    print('loaded pickle from ' + pkl_name)\n",
    "    \n",
    "    \n",
    "# check\n",
    "if which_model in rsnn_models:\n",
    "    print(f\"len(rate_maps['mem_out'].score_60)={len(rate_maps['mem_out'].score_60)}\")\n",
    "    print(f\"len(rate_maps['mem_out'].max_60_mask)={len(rate_maps['mem_out'].max_60_mask)}\")\n",
    "else:\n",
    "    print(f'len(rate_map.score_60)={len(rate_map.score_60)}')\n",
    "    print(f'len(rate_map.max_60_mask)={len(rate_map.max_60_mask)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid scales analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_model in rsnn_models:\n",
    "    grid_scales = dict()\n",
    "    for key, rate_map in rate_maps.items():\n",
    "        grid_scales[key] = rate_map.get_grid_scale()\n",
    "        print(f'{key} len: {len(grid_scales[key])}')\n",
    "else:\n",
    "    grid_scale = rate_map.get_grid_scale()\n",
    "    print(f'len(grid_scale): {len(grid_scale)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', \n",
    "#           '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#17becf']\n",
    "colors = ['Blue', 'Orange', 'Green', 'Red', \n",
    "          'Purple', 'Brown', 'Pink', 'Gray', 'Cyan']\n",
    "\n",
    "layer_labels = {\n",
    "    'spike_in': 'ISL', \n",
    "    'spike_rnn_1': 'RSL 1',\n",
    "    'spike_rnn_2': 'RSL 2',\n",
    "    'spike_rnn_3': 'RSL 3',\n",
    "    'mem_out': 'OL',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE plot of scales for LSTM and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ax = sns.kdeplot(\n",
    "    data=grid_scale, \n",
    "    # legend=True, \n",
    "    # label=which_model.upper(),\n",
    ")\n",
    "\n",
    "x = ax.get_lines()[-1].get_xdata()\n",
    "y = ax.get_lines()[-1].get_ydata()\n",
    "x_max = x[np.argmax(y)]\n",
    "\n",
    "print(which_model)\n",
    "print(f'max scale={x_max}')\n",
    "\n",
    "ax.axvline(x=x_max, linestyle='--', color='gray')\n",
    "ax.text(x=x_max, y=ax.get_ylim()[1], \n",
    "        s=f'{x_max:.2f}', ha='center', va='bottom')\n",
    "\n",
    "\n",
    "xlabel = 'Grid scale'\n",
    "plt.xlabel(xlabel)\n",
    "# plt.legend()\n",
    "\n",
    "# plt.savefig('images/grid_scales_' + options.neuron_type + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "print(f'x.shape={x.shape}')\n",
    "print(f'y.shape={y.shape}')\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "peak_indices = find_peaks(y)[0]\n",
    "x_peaks = x[peak_indices]\n",
    "y_peaks = y[peak_indices]\n",
    "\n",
    "print(\"x values at local maxima:\", x_peaks)\n",
    "print(\"y values at local maxima:\", y_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(\n",
    "    data=grid_scale, \n",
    "    # legend=True, \n",
    "    fill=True, alpha=.5, linewidth=1,\n",
    "    # label=which_model.upper(),\n",
    ")\n",
    "\n",
    "# ===============================================\n",
    "# x_peaks_draw = [x_peaks[0]]  # lstm\n",
    "x_peaks_draw = x_peaks[1:4]  # rnn\n",
    "# ===============================================\n",
    "\n",
    "for x in x_peaks_draw:\n",
    "    ax.axvline(x=x, linestyle='--', color='gray')\n",
    "    ax.text(x=x, y=ax.get_ylim()[1], \n",
    "            s=f'{x:.2f}', ha='center', va='bottom')\n",
    "\n",
    "\n",
    "for num in range(len(x_peaks_draw) - 1):\n",
    "    x_left = x_peaks_draw[num]\n",
    "    x_right = x_peaks_draw[num + 1]\n",
    "    \n",
    "    # <-> arrow\n",
    "    ax.annotate(\n",
    "        '', \n",
    "        xy    =(x_left,  ax.get_ylim()[1] * 0.9), \n",
    "        xytext=(x_right, ax.get_ylim()[1] * 0.9), \n",
    "        arrowprops=dict(arrowstyle='<->', color='blue'),\n",
    "    )\n",
    "    # ratio text\n",
    "    avg = (x_left + x_right) / 2.0\n",
    "    ratio = x_right / x_left\n",
    "    ax.text(x=avg, \n",
    "            # y=ax.get_ylim()[1] * 0.9, # lstm\n",
    "            y=ax.get_ylim()[1] * 0.91, # rnn\n",
    "            s=f'{ratio:.2f}', ha='center', va='bottom')\n",
    "\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "xlabel = 'Grid scale (m)'\n",
    "ylabel = 'Probability density'\n",
    "plt.xlabel(xlabel, fontsize=14)\n",
    "plt.ylabel(ylabel, fontsize=14)\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "plt.savefig('images/gridscales/grid_scales_' + which_model + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDE plot of scales for RSNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "max_scales = dict()\n",
    "idx_color = 0\n",
    "is_first = True\n",
    "\n",
    "for key, scale in grid_scales.items():\n",
    "    if not (key in [\n",
    "        # 'mem_in',\n",
    "        'spike_in',\n",
    "        # 'mem_rnn_1',\n",
    "        'spike_rnn_1',\n",
    "        # 'mem_rnn_2',\n",
    "        'spike_rnn_2',\n",
    "        # 'mem_rnn_3',\n",
    "        'spike_rnn_3',\n",
    "        'mem_out',\n",
    "    ]):\n",
    "        continue\n",
    "    \n",
    "    if len(scale) == 0 or len(scale) == 1:\n",
    "        continue\n",
    "    \n",
    "    if is_first:\n",
    "        ax = sns.kdeplot(\n",
    "            data=scale, \n",
    "            legend=True, \n",
    "            color=colors[idx_color], \n",
    "            label=layer_labels[key],\n",
    "        )\n",
    "        is_first = False\n",
    "    else:\n",
    "        sns.kdeplot(\n",
    "            data=scale, \n",
    "            ax=ax, \n",
    "            legend=True, \n",
    "            color=colors[idx_color], \n",
    "            label=layer_labels[key],\n",
    "        )\n",
    "    idx_color += 1\n",
    "    \n",
    "    x = ax.get_lines()[-1].get_xdata()\n",
    "    y = ax.get_lines()[-1].get_ydata()\n",
    "    x_max = x[np.argmax(y)]\n",
    "    max_scales[key] = x_max\n",
    "    # max_scales[key] = round(x_max, 2)\n",
    "    \n",
    "    print(key)\n",
    "    print(f'max scale={x_max}')\n",
    "\n",
    "\n",
    "for scale in [min(max_scales.values()), max(max_scales.values())]:\n",
    "    ax.axvline(x=scale, linestyle='--', color='gray')\n",
    "    ax.text(x=scale, y=ax.get_ylim()[1], \n",
    "            s=f'{scale:.2f}', ha='center', va='bottom')\n",
    "\n",
    "\n",
    "xlabel = 'Grid scale'\n",
    "plt.xlabel(xlabel)\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig('images/grid_scales_' + options.neuron_type + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_first = True\n",
    "for key, scale in grid_scales.items():\n",
    "    if not (key in [\n",
    "        # 'mem_in',\n",
    "        'spike_in', \n",
    "        # 'mem_rnn_1',\n",
    "        'spike_rnn_1',\n",
    "        # 'mem_rnn_2',\n",
    "        'spike_rnn_2',\n",
    "        # 'mem_rnn_3',\n",
    "        'spike_rnn_3',\n",
    "        'mem_out',\n",
    "    ]):\n",
    "        continue\n",
    "    \n",
    "    if len(scale) == 0 or len(scale) == 1:\n",
    "        continue\n",
    "    \n",
    "    if is_first:\n",
    "        ax = sns.kdeplot(\n",
    "            data=scale, \n",
    "            legend=True, \n",
    "            fill=True, alpha=.5, linewidth=1,\n",
    "            # color=colors[idx_color], \n",
    "            label=layer_labels[key],\n",
    "        )\n",
    "        is_first = False\n",
    "    else:\n",
    "        sns.kdeplot(\n",
    "            data=scale, \n",
    "            ax=ax, \n",
    "            legend=True, \n",
    "            fill=True, alpha=.5, linewidth=1,\n",
    "            # color=colors[idx_color], \n",
    "            label=layer_labels[key],\n",
    "        )\n",
    "    # idx_color += 1\n",
    "\n",
    "    \n",
    "# 2 vertical lines \n",
    "for scale in [min(max_scales.values()), max(max_scales.values())]:\n",
    "    ax.axvline(x=scale, linestyle='--', color='gray')\n",
    "    ax.text(x=scale, y=ax.get_ylim()[1], \n",
    "            s=f'{scale:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "\n",
    "# <-> arrow\n",
    "ax.annotate(\n",
    "    '', \n",
    "    xy    =(min(max_scales.values()), ax.get_ylim()[1] * 0.9), \n",
    "    xytext=(max(max_scales.values()), ax.get_ylim()[1] * 0.9), \n",
    "    arrowprops=dict(arrowstyle='<->', color='blue'),\n",
    ")\n",
    "# ratio text\n",
    "avg = (min(max_scales.values()) + max(max_scales.values())) / 2.0\n",
    "ratio = max(max_scales.values()) / min(max_scales.values())\n",
    "ax.text(x=avg, y=ax.get_ylim()[1] * 0.9, \n",
    "        s=f'{ratio:.2f}', ha='center', va='bottom')\n",
    "\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.legend(title='RSNN layer')\n",
    "\n",
    "xlabel = 'Grid scale (m)'\n",
    "ylabel = 'Probability density'\n",
    "plt.xlabel(xlabel, fontsize=14)\n",
    "plt.ylabel(ylabel, fontsize=14)\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "plt.savefig('images/gridscales/grid_scales_' + which_model + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid cells and gridness scores analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot grid cell rate maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_ratemaps_and_sacs\n",
    "\n",
    "top_num = 40  #########\n",
    "\n",
    "if which_model in lstm_rnn_models:\n",
    "    fig_rm_sac = plot_ratemaps_and_sacs(\n",
    "        rate_map,\n",
    "        title=which_model,\n",
    "        n_plot=top_num, \n",
    "        n_cols=top_num//4, \n",
    "    )\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    for layer in layer_labels.keys():\n",
    "        fig_rm_sac = plot_ratemaps_and_sacs(\n",
    "            rate_maps[layer], \n",
    "            # res=50,\n",
    "            title=which_model + '_' + layer, \n",
    "            n_plot=top_num, \n",
    "            n_cols=top_num//4, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_ratemaps_and_sacs\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "selected_num = 3\n",
    "\n",
    "\n",
    "selected_idxs = [1, 8, 17]  # lstm\n",
    "selected_idxs = [8, 17, 23]  # rnn\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# ===========================================\n",
    "# RSNN\n",
    "\n",
    "# layer = 'spike_in'\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [2, 18, 20]\n",
    "\n",
    "# layer = 'spike_rnn_1'\n",
    "# selected_idxs = [0, 1, 9]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [0, 2, 5]\n",
    "\n",
    "# layer = 'spike_rnn_2'\n",
    "# selected_idxs = [1, 2, 4]\n",
    "# selected_idxs = [0, 1, 4]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "\n",
    "# layer = 'spike_rnn_3'\n",
    "# selected_idxs = [1, 3, 5]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [0, 1, 2]\n",
    "# selected_idxs = [3, 7, 8]\n",
    "\n",
    "# layer = 'mem_out'\n",
    "# selected_idxs = [1, 10, 14]\n",
    "# selected_idxs = [0, 2, 4]\n",
    "# selected_idxs = [1, 3, 4]\n",
    "# selected_idxs = [3, 12, 17]\n",
    "# ===========================================\n",
    "# ===========================================\n",
    "\n",
    "\n",
    "if which_model in lstm_rnn_models:\n",
    "    fig_rm_sac = plot_ratemaps_and_sacs(\n",
    "        rate_map, \n",
    "        n_plot=selected_num, \n",
    "        n_cols=selected_num, \n",
    "        selected_idxs=selected_idxs,\n",
    "    )\n",
    "    # plt.savefig('images/gridcells/gridcells_' + which_model + '.pdf')\n",
    "\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    fig_rm_sac = plot_ratemaps_and_sacs(\n",
    "        rate_maps[layer], \n",
    "        n_plot=selected_num, \n",
    "        n_cols=selected_num, \n",
    "        selected_idxs=selected_idxs,\n",
    "    )\n",
    "    # plt.savefig('images/gridcells/gridcells_' + which_model + '_' + layer + '.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot rate maps of heterogeneous cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_ratemaps_and_sacs\n",
    "\n",
    "for layer in layer_labels.keys():\n",
    "    fig_rm_sac = plot_ratemaps_and_sacs(\n",
    "        rate_maps[layer], \n",
    "        title=which_model + '_' + layer, \n",
    "        n_plot=128, \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize gridness scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    for layer in layer_labels.keys():\n",
    "        print(f'------{layer}------')\n",
    "        \n",
    "        score_60 = rate_maps[layer].score_60\n",
    "        print(f'len(score_60)={len(score_60)}')\n",
    "\n",
    "        name = f'data/scores/score_{which_model}_{layer}.npy'\n",
    "        np.save(name, np.array(score_60))\n",
    "\n",
    "        avg_score_60 = np.nanmean(score_60)\n",
    "        print(f'avg_score_60={avg_score_60}')\n",
    "else:\n",
    "    print(f'------{which_model}------')\n",
    "    \n",
    "    score_60 = rate_map.score_60\n",
    "    \n",
    "    name = f'data/scores/score_{which_model}.npy'\n",
    "    np.save(name, np.array(score_60))\n",
    "\n",
    "    avg_score_60 = np.nanmean(score_60)\n",
    "    print(f'avg_score_60={avg_score_60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "layer_labels = {\n",
    "    # 'mem_in',\n",
    "    'spike_in': 'ISL', \n",
    "    # 'mem_rnn_1',\n",
    "    'spike_rnn_1': 'RSL 1',\n",
    "    # 'mem_rnn_2',\n",
    "    'spike_rnn_2': 'RSL 2',\n",
    "    # 'mem_rnn_3',\n",
    "    'spike_rnn_3': 'RSL 3',\n",
    "    'mem_out': 'OL',\n",
    "}\n",
    "\n",
    "lstm_rnn_models = ['lstm', 'rnn']\n",
    "rsnn_models = ['if', 'lif', 'alif', 'dexat', 'texat']\n",
    "\n",
    "# load all scores\n",
    "scores = {\n",
    "    'lstm': np.load('data/scores/score_lstm.npy'),\n",
    "    'rnn':  np.load('data/scores/score_rnn.npy'),\n",
    "    'if': {\n",
    "        'spike_in':    np.load('data/scores/score_if_spike_in.npy'),\n",
    "        'spike_rnn_1': np.load('data/scores/score_if_spike_rnn_1.npy'),\n",
    "        'spike_rnn_2': np.load('data/scores/score_if_spike_rnn_2.npy'),\n",
    "        'spike_rnn_3': np.load('data/scores/score_if_spike_rnn_3.npy'),\n",
    "        'mem_out':     np.load('data/scores/score_if_mem_out.npy'),\n",
    "    },\n",
    "    'lif': {\n",
    "        'spike_in':    np.load('data/scores/score_lif_spike_in.npy'),\n",
    "        'spike_rnn_1': np.load('data/scores/score_lif_spike_rnn_1.npy'),\n",
    "        'spike_rnn_2': np.load('data/scores/score_lif_spike_rnn_2.npy'),\n",
    "        'spike_rnn_3': np.load('data/scores/score_lif_spike_rnn_3.npy'),\n",
    "        'mem_out':     np.load('data/scores/score_lif_mem_out.npy'),\n",
    "    },\n",
    "    'alif': {\n",
    "        'spike_in':    np.load('data/scores/score_alif_spike_in.npy'),\n",
    "        'spike_rnn_1': np.load('data/scores/score_alif_spike_rnn_1.npy'),\n",
    "        'spike_rnn_2': np.load('data/scores/score_alif_spike_rnn_2.npy'),\n",
    "        'spike_rnn_3': np.load('data/scores/score_alif_spike_rnn_3.npy'),\n",
    "        'mem_out':     np.load('data/scores/score_alif_mem_out.npy'),\n",
    "    },\n",
    "    'dexat': {\n",
    "        'spike_in':    np.load('data/scores/score_dexat_spike_in.npy'),\n",
    "        'spike_rnn_1': np.load('data/scores/score_dexat_spike_rnn_1.npy'),\n",
    "        'spike_rnn_2': np.load('data/scores/score_dexat_spike_rnn_2.npy'), \n",
    "        'spike_rnn_3': np.load('data/scores/score_dexat_spike_rnn_3.npy'),\n",
    "        'mem_out':     np.load('data/scores/score_dexat_mem_out.npy'),\n",
    "    },\n",
    "    'texat': {\n",
    "        'spike_in':    np.load('data/scores/score_texat_spike_in.npy'),\n",
    "        'spike_rnn_1': np.load('data/scores/score_texat_spike_rnn_1.npy'),\n",
    "        'spike_rnn_2': np.load('data/scores/score_texat_spike_rnn_2.npy'), \n",
    "        'spike_rnn_3': np.load('data/scores/score_texat_spike_rnn_3.npy'),\n",
    "        'mem_out':     np.load('data/scores/score_texat_mem_out.npy'),\n",
    "    },\n",
    "}\n",
    "\n",
    "# convert nan to -inf\n",
    "for model in scores.keys():\n",
    "    if model in lstm_rnn_models:\n",
    "        scores[model] = np.nan_to_num(scores[model], nan=-np.inf)\n",
    "    elif model in rsnn_models:\n",
    "        for layer in scores[model].keys():\n",
    "            scores[model][layer] = np.nan_to_num(scores[model][layer], nan=-np.inf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute grid cell proportion: score > gridness threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_thresh = 0.37\n",
    "\n",
    "def compute_ratio(values, threshold):\n",
    "    total_count = len(values)\n",
    "    greater_than_threshold_count = sum(1 for value in values if value > threshold)\n",
    "    ratio = float(greater_than_threshold_count) / float(total_count)\n",
    "    return ratio\n",
    "\n",
    "\n",
    "for model in scores.keys():\n",
    "    print('------')\n",
    "    if model in lstm_rnn_models:\n",
    "        print(f'model={model}')\n",
    "        \n",
    "        ratio = compute_ratio(scores[model], grid_thresh)\n",
    "        ratio = round(ratio * 100, 1)\n",
    "        print(ratio)\n",
    "    elif model in rsnn_models:\n",
    "        print(f'model={model}')\n",
    "        for layer in scores[model].keys():\n",
    "            print(f'layer={layer}')\n",
    "            \n",
    "            ratio = compute_ratio(scores[model][layer], grid_thresh)\n",
    "            ratio = round(ratio * 100, 1)\n",
    "            print(ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute average scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average scores\n",
    "avg_scores = dict()\n",
    "std_err = dict()\n",
    "\n",
    "top_num = 10  #########\n",
    "\n",
    "for model in scores.keys():\n",
    "    if model in lstm_rnn_models:\n",
    "        s_no_nan = scores[model]\n",
    "        top_scores = np.sort(s_no_nan)[-top_num:]\n",
    "        # mean\n",
    "        avg_scores[model] = np.mean(top_scores)\n",
    "        # std err of mean\n",
    "        std_err[model] = np.std(top_scores) / np.sqrt(len(top_scores))\n",
    "        \n",
    "    elif model in rsnn_models:\n",
    "        avg_scores[model] = dict()\n",
    "        std_err[model] = dict()\n",
    "        \n",
    "        for layer in scores[model].keys():\n",
    "            s_no_nan = scores[model][layer]\n",
    "            top_scores = np.sort(s_no_nan)[-top_num:]\n",
    "            # mean\n",
    "            avg_scores[model][layer] = np.mean(top_scores)\n",
    "            # std err of mean\n",
    "            std_err[model][layer] = np.std(top_scores) / np.sqrt(len(top_scores))\n",
    "\n",
    "print(avg_scores)\n",
    "print(std_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize average scores, bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['Blue', 'Orange', 'Green', 'Red', 'Purple', 'Brown', 'Pink', 'Gray', 'Cyan']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#17becf']\n",
    "# darker versions:\n",
    "# colors = ['#134d72', '#b3540a', '#194019', '#851b1b', '#5c4380', '#573d30', '#89497e', '#4c4c4c', '#107288']\n",
    "# colors = ['#184f81', '#cc660b', '#238327', '#aa2121', '#775593', '#70483d', '#b9609b', '#666666', '#1392a8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X labels\n",
    "x_labels = [\n",
    "    model.upper() if model in lstm_rnn_models else (model.upper() + '-RSNN')\n",
    "    for model in avg_scores.keys()\n",
    "]\n",
    "\n",
    "# Define the x-axis positions for each group\n",
    "# x = np.arange(len(x_labels))\n",
    "x = [\n",
    "    0,\n",
    "    0.4,\n",
    "    1.1,\n",
    "    1.1 + 1.0,\n",
    "    1.1 + 2.0,\n",
    "    1.1 + 3.0,\n",
    "    1.1 + 4.0,\n",
    "]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, model in enumerate(avg_scores.keys()):\n",
    "    if model in lstm_rnn_models:\n",
    "        ax.bar(\n",
    "            x[i], avg_scores[model], \n",
    "            ###\n",
    "            yerr=std_err[model], \n",
    "            capsize=3,\n",
    "            ###\n",
    "            color='gray', \n",
    "            width=0.12, \n",
    "        )\n",
    "        \n",
    "    elif model in rsnn_models:\n",
    "        for j, layer in enumerate(avg_scores[model].keys()):\n",
    "            ax.bar(\n",
    "                x[i] + j * 0.15 - 0.3, avg_scores[model][layer], \n",
    "                ###\n",
    "                yerr=std_err[model][layer], \n",
    "                capsize=3,\n",
    "                ###\n",
    "                color=colors[j], \n",
    "                width=0.12, \n",
    "                label=layer_labels[layer],\n",
    "            )\n",
    "\n",
    "\n",
    "# Add horizontal line at y=0 for reference\n",
    "plt.axhline(avg_scores['lstm'], color='gray', linestyle='--', linewidth=1)\n",
    "plt.axhline(avg_scores['rnn'], color='gray', linestyle='--', linewidth=1)\n",
    "# plt.axhline(0.37, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "   \n",
    "# Set labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(x_labels, fontsize=10)\n",
    "\n",
    "ax.set_xlabel(\"Model\", fontsize=14)\n",
    "ax.set_ylabel(\"Grid score\", fontsize=14)\n",
    "# ax.set_title(f\"Average gridness score for top {top_num} grid cells\", fontsize=16)\n",
    "\n",
    "# Add legend\n",
    "axhandles, axlabels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(axlabels, axhandles))  # Remove duplicate labels\n",
    "ax.legend(by_label.values(), by_label.keys(), \n",
    "          title='RSNN layer',\n",
    "          loc=\"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('images/gridness_scores.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State space properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "res = 50 #20\n",
    "\n",
    "origins = np.stack(np.mgrid[:3, :3] - 1) * res//4 + res//2\n",
    "# print(f'origins={origins}')\n",
    "\n",
    "n_grid_cells = 128 #4096 #1024\n",
    "\n",
    "###### RSNN ######\n",
    "# layer = 'spike_in'\n",
    "# layer = 'spike_rnn_1'\n",
    "# layer = 'spike_rnn_2'\n",
    "# layer = 'spike_rnn_3'\n",
    "layer = 'mem_out'\n",
    "\n",
    "grid_sort = np.flip(np.argsort(rate_maps[layer].score_60))\n",
    "rate_map = rate_maps[layer].ratemaps\n",
    "\n",
    "###### RNN ######\n",
    "# grid_sort = np.flip(np.argsort(rate_map.score_60))\n",
    "# rate_map = rate_map.ratemaps\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.subplot(3, 3, 3*i + j + 1)\n",
    "        x = origins[0, i, j]\n",
    "        y = origins[1, i, j]\n",
    "        \n",
    "        r0 = rate_map[grid_sort[:n_grid_cells], x, y]\n",
    "        r0 = r0.reshape(-1, 1, 1)\n",
    "        \n",
    "        dr0 = r0\n",
    "        dr1 = rate_map[grid_sort[:n_grid_cells]]\n",
    "        # dr0 = dr0.reshape(dr0.shape[0], -1)\n",
    "        # dr1 = dr1.reshape(dr1.shape[0], -1)\n",
    "        dists = np.linalg.norm(dr0 - dr1, axis=0)\n",
    "        # print(f'dr0.shape={dr0.shape}')\n",
    "        # print(f'dr1.shape={dr1.shape}')\n",
    "        # print(f'dists.shape={dists.shape}')\n",
    "        \n",
    "        im = plt.imshow(dists.reshape(res, res) / np.max(dists),\n",
    "                        cmap='viridis_r', \n",
    "                        # cmap='jet', \n",
    "                        interpolation='gaussian')\n",
    "        plt.axis('off')\n",
    "        plt.scatter(y, x, marker='x', c='black')\n",
    "        \n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.12, 0.02, 0.74])\n",
    "cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "cbar.ax.locator_params(nbins=3)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.outline.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# res = 20\n",
    "res = 50\n",
    "\n",
    "# n_grid_cells = 128\n",
    "# n_grid_cells = 1024\n",
    "# n_grid_cells = 2048\n",
    "n_grid_cells = 4096\n",
    "\n",
    "if which_model in rsnn_models:\n",
    "    ###### RSNN ######\n",
    "    # layer = 'spike_in'\n",
    "    # layer = 'spike_rnn_1'\n",
    "    layer = 'spike_rnn_2'\n",
    "    # layer = 'spike_rnn_3'\n",
    "    # layer = 'mem_out'\n",
    "\n",
    "    grid_sort = np.flip(np.argsort(rate_maps[layer].score_60))\n",
    "\n",
    "    rate_map = rate_maps[layer].ratemaps\n",
    "    print(f'rate_map.shape={rate_map.shape}')\n",
    "\n",
    "    rate_map = rate_map[grid_sort[:n_grid_cells]]\n",
    "    print(f'rate_map.shape={rate_map.shape}')\n",
    "    \n",
    "else:\n",
    "    grid_sort = np.flip(np.argsort(rate_map.score_60))\n",
    "\n",
    "    rate_map = rate_map.ratemaps\n",
    "    print(f'rate_map.shape={rate_map.shape}')\n",
    "\n",
    "    rate_map = rate_map[grid_sort[:n_grid_cells]]\n",
    "    print(f'rate_map.shape={rate_map.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Fourier transform \n",
    "# Ng = options.Ng\n",
    "Ng = n_grid_cells\n",
    "\n",
    "rm_fft_real = np.zeros([Ng, res, res])\n",
    "rm_fft_imag = np.zeros([Ng, res, res])\n",
    "\n",
    "for i in tqdm(range(Ng)):\n",
    "    rm_fft_real[i] = np.real(np.fft.fft2(rate_map[i].reshape([res, res])))\n",
    "    rm_fft_imag[i] = np.imag(np.fft.fft2(rate_map[i].reshape([res, res])))\n",
    "    \n",
    "rm_fft = rm_fft_real + 1j * rm_fft_imag\n",
    "\n",
    "im = (np.real(rm_fft)**2).mean(0)\n",
    "im[0, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "width = 6\n",
    "idxs = np.arange(-width + 1, width)\n",
    "x2, y2 = np.meshgrid(\n",
    "    # np.arange(2*width - 1),\n",
    "    # np.arange(2*width - 1),\n",
    "    np.arange(-width+1, width),\n",
    "    np.arange(-width+1, width),\n",
    ")\n",
    "\n",
    "# scatter = plt.scatter(x2, y2, c=im[idxs][:, idxs], s=600, cmap='Oranges')  # circle\n",
    "scatter = ax.scatter(x2, y2, c=im[idxs][:, idxs], marker='s', s=500, cmap='Oranges')  # square\n",
    "# scatter = ax.scatter(x2, y2, c=im[idxs][:, idxs], marker='s', s=500, cmap='Blues')  # square\n",
    "\n",
    "# color bar\n",
    "cbar = plt.colorbar(scatter, shrink=0.6, pad=0.0)\n",
    "cbar.set_ticks([cbar.vmin, cbar.vmax])  # Set ticks at the minimum and maximum\n",
    "cbar.set_ticklabels(['Low', 'High'])    # Set the labels\n",
    "\n",
    "# origin\n",
    "ax.scatter(0, 0, color='black', s=10)\n",
    "\n",
    "# ==============================\n",
    "###### 'spike_rnn_1' ######\n",
    "# k1 = [2,1]\n",
    "# k2 = [0,2]\n",
    "# k3 = [-1,2]\n",
    "###### 'spike_rnn_2' ######\n",
    "k1 = [2,1]\n",
    "k2 = [0,2]\n",
    "k3 = [-2,1]\n",
    "###### 'spike_rnn_3' ###### res50\n",
    "# k1 = [2,1]\n",
    "# k2 = [0,2]\n",
    "# k3 = [-2,1]\n",
    "###### 'mem_out' ######\n",
    "# k1 = [3,0]\n",
    "# k2 = [1,3]\n",
    "# k3 = [-2,2]\n",
    "# res50\n",
    "# k1 = [1,1]\n",
    "# k2 = [0,1]\n",
    "# k3 = [-1,1]\n",
    "\n",
    "\n",
    "###### rnn ######\n",
    "# k1 = [3,0]\n",
    "# k2 = [1,2]\n",
    "# k3 = [-2,2]\n",
    "\n",
    "# draw arrows\n",
    "for i, k in enumerate([k1, k2, k3]):\n",
    "    # k arrow\n",
    "    # plt.arrow(0, 0, \n",
    "    #           k[1], k[0], \n",
    "    #           head_width=0.05, head_length=0.05, fc='k', ec='k')\n",
    "    arrow = FancyArrowPatch(\n",
    "        (0, 0), \n",
    "        (k[1], k[0]), \n",
    "        arrowstyle=\"->\",       # Arrow style\n",
    "        color=\"black\",         # Arrow color\n",
    "        mutation_scale=10      # Scale of the arrowhead\n",
    "    )\n",
    "    ax.add_patch(arrow)\n",
    "    \n",
    "    if i == 0:\n",
    "        xytext = (k[1]/2.0 + 0.15, k[0]/2.0)\n",
    "        # xytext = (k[1]/2.0 + 0.1, k[0]/2.0)\n",
    "    elif i == 1:\n",
    "        xytext = (k[1]/2.0, k[0]/2.0 + 0.1)\n",
    "        # xytext = (k[1]/2.0, k[0]/2.0 + 0.3)\n",
    "    elif i == 2:\n",
    "        xytext = (k[1]/2.0 + 0.1, k[0]/2.0 )\n",
    "    plt.annotate(f'$k_{i+1}$', \n",
    "                 xy=(k[1], k[0]), \n",
    "                 xytext=xytext, \n",
    "                 textcoords='data')\n",
    "\n",
    "    # -k arrow\n",
    "    # plt.arrow(0, 0, \n",
    "    #           -k[1], -k[0], \n",
    "    #           head_width=0.1, head_length=0.1, fc='k', ec='k')\n",
    "    arrow = FancyArrowPatch(\n",
    "        (0, 0), \n",
    "        (-k[1], -k[0]), \n",
    "        arrowstyle=\"->\",       # Arrow style\n",
    "        color=\"black\",         # Arrow color\n",
    "        mutation_scale=10      # Scale of the arrowhead\n",
    "    )\n",
    "    ax.add_patch(arrow)\n",
    "    if i == 0:\n",
    "        xytext = (-k[1]/2.0 - 0.7, -k[0]/2.0)\n",
    "    elif i == 1:\n",
    "        xytext = (-k[1]/2.0 - 0.5, -k[0]/2.0 + 0.1)\n",
    "        # xytext = (-k[1]/2.0 - 0.5, -k[0]/2.0 + 0.2)\n",
    "    elif i == 2:\n",
    "        xytext = (-k[1]/2.0 - 0.75, -k[0]/2.0)\n",
    "        # xytext = (-k[1]/2.0 - 0.75, -k[0]/2.0 - 0.1)\n",
    "    plt.annotate(f'$-k_{i+1}$', \n",
    "                 xy=(-k[1], -k[0]), \n",
    "                 xytext=xytext, \n",
    "                 textcoords='data')\n",
    "    \n",
    "# draw dotted lines\n",
    "xlist = [\n",
    "    [k1[1], k2[1]],\n",
    "    [k2[1], k3[1]],\n",
    "    [k3[1], -k1[1]],\n",
    "    [-k1[1], -k2[1]],\n",
    "    [-k2[1], -k3[1]],\n",
    "    [-k3[1], k1[1]],\n",
    "]\n",
    "ylist = [\n",
    "    [k1[0], k2[0]],\n",
    "    [k2[0], k3[0]],\n",
    "    [k3[0], -k1[0]],\n",
    "    [-k1[0], -k2[0]],\n",
    "    [-k2[0], -k3[0]],\n",
    "    [-k3[0], k1[0]],\n",
    "]\n",
    "for i in range(len(xlist)):\n",
    "    x = xlist[i]\n",
    "    y = ylist[i]\n",
    "    plt.plot(x, y, linestyle='dotted', color='blue', alpha=0.8)\n",
    "# ==============================\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.axis('off')\n",
    "# plt.title('Mean Fourier Power')\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/statespace/mean_fourier_power.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/statespace/mean_fourier_power_res50.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "# plt.savefig('images/statespace/mean_fourier_power_rnn.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k4 = k5 = k6 = k1\n",
    "\n",
    "freq = 1\n",
    "ks = freq * np.array([k1, k2, k3, k4, k5, k6])\n",
    "ks = ks.astype('int')\n",
    "\n",
    "modes = np.stack([rm_fft[:, k[0], k[1]] for k in ks])\n",
    "\n",
    "# Find phases\n",
    "phases = [np.angle(mode) for mode in modes]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.scatter(phases[0], phases[1], c='black', s=10)\n",
    "plt.xlabel(r'$\\phi_1$')\n",
    "plt.ylabel(r'$\\phi_2$')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.scatter(phases[1], phases[2], c='black', s=10)\n",
    "plt.xlabel(r'$\\phi_2$')\n",
    "plt.ylabel(r'$\\phi_3$')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(phases[2], phases[0], c='black', s=10)\n",
    "plt.xlabel(r'$\\phi_3$')\n",
    "plt.ylabel(r'$\\phi_1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(phases[0], phases[1], phases[2], c='black', s=10)\n",
    "ax.view_init(azim=60)\n",
    "\n",
    "# ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "# ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "# ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "\n",
    "# ax.xaxis._axinfo[\"grid\"]['color'] = (1,1,1,0)\n",
    "# ax.yaxis._axinfo[\"grid\"]['color'] = (1,1,1,0)\n",
    "# ax.zaxis._axinfo[\"grid\"]['color'] = (1,1,1,0)\n",
    "\n",
    "ax.set_xlabel(r'$\\phi_1$', fontsize=16)\n",
    "ax.set_ylabel(r'$\\phi_2$', fontsize=16)\n",
    "ax.set_zlabel(r'$\\phi_3$', fontsize=16)\n",
    "\n",
    "# plt.title('Phase distribution')\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/statespace/phase_distribution.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/statespace/phase_distribution_200.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "# plt.savefig('images/statespace/phase_distribution_rnn.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 5.0\n",
    "r = 2.0\n",
    "\n",
    "# =====================\n",
    "phi   = phases[0]\n",
    "theta = phases[1]\n",
    "# =====================\n",
    "\n",
    "x = (R + r * np.cos(phi)) * np.cos(theta)\n",
    "y = (R + r * np.cos(phi)) * np.sin(theta)\n",
    "z = r * np.sin(phi)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(\n",
    "    x, y, z, \n",
    "    # c='lightgreen', \n",
    "    c=np.cos((phi - 0.3) % (2 * np.pi)), \n",
    "    # c=z, \n",
    "    cmap='viridis', \n",
    "    # cmap='summer', \n",
    "    alpha=0.8,\n",
    "    s=60,\n",
    ")\n",
    "\n",
    "ax.axis('off')\n",
    "ax.view_init(elev=60, azim=0)\n",
    "\n",
    "# ax.set_xlim([-5, 5])\n",
    "# ax.set_ylim([-5, 5])\n",
    "# ax.set_zlim([-10, 10])\n",
    "# ax.set_zlim(-r/2, r/2)\n",
    "\n",
    "# Toroidal topology\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('images/statespace/toroidal_topology.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/statespace/toroidal_topology_rnn.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "freq = 1\n",
    "crop = 0\n",
    "cmaps = ['Blues', 'Oranges', 'Greens']\n",
    "\n",
    "x = np.mgrid[:res, :res] * 2 * np.pi / res\n",
    "x = x.reshape(2, -1)\n",
    "k = freq * np.stack([k1, k2, k3])\n",
    "X = np.concatenate([np.cos(k.dot(x)), np.sin(k.dot(x))], axis=0)\n",
    "# print(f'X[0].shape={X[0].shape}')\n",
    "\n",
    "idxs1, idxs2 = np.mgrid[crop:res-crop, crop:res-crop]\n",
    "idxs = np.ravel_multi_index((idxs1, idxs2), (res, res)).ravel()\n",
    "# print(f'idxs={idxs}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    B = np.stack([np.cos(phases[i]), np.sin(phases[i])])\n",
    "    test = B @ (rate_map.reshape([Ng, -1]))\n",
    "    \n",
    "    plt.scatter(test[0], test[1], c=X[i][idxs], cmap=cmaps[i], s=30)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title(f'$k_{i+1}$')\n",
    "    \n",
    "# plt.savefig('images/statespace/projections.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/statespace/projections_res50.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.savefig('images/statespace/projections_200_res50.pdf', format='pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'B.shape={B.shape}')\n",
    "print(f'phases[0].shape={phases[0].shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gridcell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "342px",
    "left": "22px",
    "top": "110px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
